{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fba9dc6",
   "metadata": {},
   "source": [
    "## Data Sources:\n",
    "- Memory Alpha for Metadata & Summaries\n",
    "- Chakoteya.com for Lines\n",
    "\n",
    "## Tasks\n",
    "\n",
    "* scrape lines\n",
    "* scrape episodes list w/ metadata\n",
    "* scrape episodes' summaries\n",
    "\n",
    "* cleaning & exploration\n",
    "    * NAs\n",
    "    * duplicates\n",
    "    * dates\n",
    "    * titles [need to match in both sources]\n",
    "    * lines & characters (#)\n",
    "    * text (#)\n",
    "    \n",
    "(#) remove website specific parts e.g. copyright statements [pre-cleaning step]\n",
    "\n",
    "* explore\n",
    "    - how many episodes\n",
    "    - how many lines / per series / per episode / per character\n",
    "    - how many characters / per series \n",
    "\n",
    "* build corpus [script/function to clean long text]\n",
    "    1. expansion\n",
    "    2. normalization\n",
    "    3. tokenization\n",
    "    4. stop words removal\n",
    "    5. stemming / lemmatization\n",
    "    \n",
    "## Before Modeling\n",
    "\n",
    "* Datasets\n",
    "    - episode list w/ metadata\n",
    "        | Series | Seasons | Episodes | Originally released | In Dataset |\n",
    "        | :----: | :----: | :----: | :----: | :----: |\n",
    "    - episode lines joined to transcript w/o characters w/ metadata\n",
    "        | Series | Seasons | Episodes | Originally released | In Dataset |\n",
    "        | :----: | :----: | :----: | :----: | :----: |\n",
    "    - episode lines w/ characters & metadata\n",
    "        | Series | Seasons | Episodes | Originally released | In Dataset |\n",
    "        | :----: | :----: | :----: | :----: | :----: |\n",
    "    - episode summaries w/ metadata\n",
    "        | Series | Seasons | Episodes | Originally released | In Dataset |\n",
    "        | :----: | :----: | :----: | :----: | :----: |\n",
    "    \n",
    "* Document-Term-Matrix\n",
    "    - corpus 1: transcripts\n",
    "    - corpus 2: summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5aeda2",
   "metadata": {},
   "source": [
    "## Concepts & mathematical representations\n",
    "\n",
    "* Document-Term-Matrix\n",
    "* Bag-of-Words & alternative: Word2Vec\n",
    "* tf-idf & term frequency, document frequency, idf / log\n",
    "* normalization\n",
    "* expansion\n",
    "* tokenization\n",
    "* stop words\n",
    "* stemming\n",
    "* lemmatization\n",
    "* term\n",
    "* document\n",
    "* corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd25da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

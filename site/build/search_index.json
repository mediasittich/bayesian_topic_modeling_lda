[["index.html", "Bayesian Topic Modelling: Latent Dirichlet Allocation and its Applications Chapter 1 Introduction", " Bayesian Topic Modelling: Latent Dirichlet Allocation and its Applications Regina Galambos 2021-07-13 Chapter 1 Introduction This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["theory.html", "Chapter 2 Theory", " Chapter 2 Theory You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 3. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. "],["bayes-rule.html", "2.1 Bayes’ Rule", " 2.1 Bayes’ Rule \\[\\begin{equation*} p(\\theta|x) = \\frac{p(x|\\theta)p(\\theta)}{p(x)} \\end{equation*}\\] knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2021) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). "],["dirichlet-distribution.html", "2.2 Dirichlet Distribution", " 2.2 Dirichlet Distribution Beta and stuff "],["multinomial-distribution.html", "2.3 Multinomial Distribution", " 2.3 Multinomial Distribution Binomial and stuff "],["mixture-models.html", "2.4 Mixture Models", " 2.4 Mixture Models what’s that "],["lda-theory.html", "Chapter 3 Latent Dirichlet Allocation", " Chapter 3 Latent Dirichlet Allocation We describe our methods in this chapter. Math can be added in body using usual syntax like this "],["what-is-lda.html", "3.1 What is LDA?", " 3.1 What is LDA? \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\] You can also use math in footnotes like this1. We will approximate standard error to 0.0272 where we mention \\(p = \\frac{a}{b}\\)↩︎ \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\]↩︎ "],["how-does-it-work.html", "3.2 How does it work?", " 3.2 How does it work? difficult math things go here "],["case-study.html", "Chapter 4 Case Study", " Chapter 4 Case Study Some significant applications are demonstrated in this chapter. library(tidyverse) library(tidytext) library(tm) library(topicmodels) library(topicdoc) library(stringr) library(wordcloud) library(RColorBrewer) data(&quot;AssociatedPress&quot;, package = &quot;topicmodels&quot;) 4.0.1 Document-Term-Matrix AssociatedPress &lt;&lt;DocumentTermMatrix (documents: 2246, terms: 10473)&gt;&gt; Non-/sparse entries: 302031/23220327 Sparsity : 99% Maximal term length: 18 Weighting : term frequency (tf) The data set is an object of class “DocumentTermMatrix” provided by package tm. It is a document-term matrix which contains the term frequency of 10473 terms in 2246 documents. terms &lt;- Terms(AssociatedPress) summary(terms) Length Class Mode 10473 character character head(terms) [1] &quot;aaron&quot; &quot;abandon&quot; &quot;abandoned&quot; [4] &quot;abandoning&quot; &quot;abbott&quot; &quot;abboud&quot; ap_td &lt;- tidy(AssociatedPress) ap_td # A tibble: 302,031 x 3 document term count &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 adding 1 2 1 adult 2 3 1 ago 1 4 1 alcohol 1 5 1 allegedly 1 6 1 allen 1 7 1 apparently 2 8 1 appeared 1 9 1 arrested 1 10 1 assault 1 # … with 302,021 more rows 4.0.2 Split data for training &amp; test # Select first 500 articles full_data &lt;- AssociatedPress[1:500, ] # create train and test sets n &lt;- nrow(full_data) splitter &lt;- sample(1:n, round(n * 0.8)) train_set &lt;- full_data[splitter, ] test_set &lt;- full_data[-splitter, ] 4.0.3 Train models for different k # fit models with different k n_topics &lt;- c(2, 4, 10, 20, 50, 100) ap_lda_models &lt;- n_topics %&gt;% map(LDA, x = train_set, control = list(seed = 42)) # Select model with k = 2 ap_lda_models[[1]] A LDA_VEM topic model with 2 topics. 4.0.4 Word-topic-probabilities for k = 2 # Word-Topic-probabilities ap_topics &lt;- tidy(ap_lda_models[[1]], matrix = &quot;beta&quot;) ap_topics # A tibble: 20,946 x 3 topic term beta &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 aaron 3.54e- 5 2 2 aaron 6.91e- 5 3 1 abandon 4.94e- 5 4 2 abandon 1.65e- 6 5 1 abandoned 3.66e- 5 6 2 abandoned 1.21e- 4 7 1 abandoning 6.50e-121 8 2 abandoning 2.64e- 5 9 1 abbott 1.97e- 12 10 2 abbott 5.28e- 5 # … with 20,936 more rows 4.0.5 Top Words in Topics ap_top_terms &lt;- ap_topics %&gt;% group_by(topic) %&gt;% slice_max(beta, n = 10) %&gt;% ungroup() %&gt;% arrange(topic, -beta) ap_top_terms %&gt;% mutate(term = reorder_within(term, beta, topic)) %&gt;% ggplot(aes(beta, term, fill = factor(topic))) + geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = &quot;free&quot;) + scale_y_reordered() ### Document-topic probabilities ap_documents &lt;- tidy(ap_lda_models[[1]], matrix = &quot;gamma&quot;) ap_documents # A tibble: 800 x 3 document topic gamma &lt;int&gt; &lt;int&gt; &lt;dbl&gt; 1 1 1 1.00 2 2 1 1.00 3 3 1 0.999 4 4 1 0.514 5 5 1 0.000497 6 6 1 0.999 7 7 1 0.991 8 8 1 0.000234 9 9 1 0.00198 10 10 1 1.00 # … with 790 more rows 4.0.6 Top 5 words in each topic ap_lda_td &lt;- tidy(ap_lda_models[[1]]) top_terms &lt;- ap_lda_td %&gt;% group_by(topic) %&gt;% top_n(5, beta) %&gt;% ungroup() %&gt;% arrange(topic, -beta) top_terms # A tibble: 10 x 3 topic term beta &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 percent 0.00807 2 1 soviet 0.00664 3 1 new 0.00638 4 1 government 0.00485 5 1 year 0.00449 6 2 i 0.00750 7 2 people 0.00499 8 2 state 0.00401 9 2 president 0.00361 10 2 new 0.00352 4.0.7 Word-topic-probabilities for k = 20 # Word-Topic-probabilities ap_topics_20 &lt;- tidy(ap_lda_models[[4]], matrix = &quot;beta&quot;) ap_topics_20 # A tibble: 209,460 x 3 topic term beta &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 aaron 1.46e-151 2 2 aaron 2.49e- 4 3 3 aaron 6.09e-152 4 4 aaron 3.12e-117 5 5 aaron 1.31e-151 6 6 aaron 9.82e-152 7 7 aaron 8.09e-152 8 8 aaron 1.20e-117 9 9 aaron 7.46e-152 10 10 aaron 2.07e-151 # … with 209,450 more rows 4.0.8 Top Words in Topics ap_top_terms &lt;- ap_topics_20 %&gt;% group_by(topic) %&gt;% slice_max(beta, n = 10) %&gt;% ungroup() %&gt;% arrange(topic, -beta) ap_top_terms %&gt;% mutate(term = reorder(term, beta)) %&gt;% ggplot(aes(term, beta, fill = factor(topic))) + geom_bar(stat = &quot;identity&quot;, show.legend = FALSE) + facet_wrap(~ topic, scales = &quot;free&quot;, ncol = 3) + coord_flip() ### How well does the model predict? - Evaluate with Perplexity 4.0.8.1 k = 2 print(&quot;Test set - Model 1&quot;) [1] &quot;Test set - Model 1&quot; perplexity(ap_lda_models[[1]], newdata = test_set) [1] 386779.4 4.0.8.2 k = 4 print(&quot;Test set - Model 2&quot;) [1] &quot;Test set - Model 2&quot; perplexity(ap_lda_models[[2]], newdata = test_set) [1] 382493.5 4.0.8.3 k = 10 print(&quot;Training set - Model 3&quot;) [1] &quot;Training set - Model 3&quot; perplexity(ap_lda_models[[3]], newdata = train_set) [1] 1746.543 print(&quot;Test set - Model 3&quot;) [1] &quot;Test set - Model 3&quot; perplexity(ap_lda_models[[3]], newdata = test_set) [1] 394821.4 4.0.8.4 k = 20 print(&quot;Test set - Model 4&quot;) [1] &quot;Test set - Model 4&quot; perplexity(ap_lda_models[[4]], newdata = test_set) [1] 422952.7 4.0.8.5 k = 50 print(&quot;Test set - Model 5&quot;) [1] &quot;Test set - Model 5&quot; perplexity(ap_lda_models[[5]], newdata = test_set) [1] 423337.2 4.0.8.6 k = 100 print(&quot;Test set - Model 6&quot;) [1] &quot;Test set - Model 6&quot; perplexity(ap_lda_models[[6]], newdata = test_set) [1] 442869.4 data_frame(k = n_topics, perplex = map_dbl(ap_lda_models, perplexity)) %&gt;% ggplot(aes(k, perplex)) + geom_point() + geom_line() + labs(title = &quot;Evaluating LDA topic models on training set&quot;, subtitle = &quot;Optimal number of topics (smaller is better)&quot;, x = &quot;Number of topics&quot;, y = &quot;Perplexity&quot;) "]]
